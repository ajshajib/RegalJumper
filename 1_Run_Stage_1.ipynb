{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fab7ed739ebc36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Author:** Anowar Shajib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab7a45bd348bd3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1432c1c01ddb544",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_pipeline = True\n",
    "rate_file_directory_for_processing = stage1_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f58916e80a6df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STAGE 1 DETECTOR PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b7a3509f0fbe0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to call the detector1 pipeline with desired parameters.\n",
    "# Individual steps not enumerated. Options can be set as commented overrides.\n",
    "\n",
    "\n",
    "def run_spec1_pipeline(file_name, output_directory):\n",
    "    \"\"\"\n",
    "    Create a Detector1Pipeline object and set all the desired stage 1\n",
    "    pipeline processing arguments.\n",
    "\n",
    "    :param file_name: _uncal.fits exposure file name\n",
    "    :param output_directory: Directory for the stage 1 output files\n",
    "    :return: None\n",
    "    :outputs: writes  _rate.fits and _rateints.fits files in `outdir`\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Running Detector1Pipeline on {0:s}...\".format(file_name))\n",
    "\n",
    "    crds_config = Detector1Pipeline.get_config_from_reference(file_name)\n",
    "    detector_1_pipeline = Detector1Pipeline.from_config_section(crds_config)\n",
    "    detector_1_pipeline.output_dir = output_directory\n",
    "\n",
    "    # Overrides for whether or not certain steps should be skipped\n",
    "    # detector_1_pipeline.dq_init.skip = False\n",
    "    # detector_1_pipeline.saturation.skip = False\n",
    "    # detector_1_pipeline.firstframe.skip = False\n",
    "    # detector_1_pipeline.lastframe.skip = False\n",
    "    # detector_1_pipeline.reset.skip = False\n",
    "    # detector_1_pipeline.linearity.skip = False\n",
    "    # detector_1_pipeline.rscd.skip = False\n",
    "    # detector_1_pipeline.dark_current.skip = False\n",
    "    # detector_1_pipeline.refpix.skip = False\n",
    "    # detector_1_pipeline.jump.skip = False\n",
    "    # detector_1_pipeline.ramp_fit.skip = False\n",
    "    # detector_1_pipeline.gain_scale.skip = False\n",
    "\n",
    "    # Turn on multiprocessing for jump and ramp fitting steps\n",
    "    detector_1_pipeline.jump.maximum_cores = \"half\"\n",
    "    detector_1_pipeline.ramp_fit.maximum_cores = \"half\"\n",
    "\n",
    "    # S_DARK  = 'COMPLETE'           / Dark Subtraction\n",
    "    # S_DQINIT= 'COMPLETE'           / Data Quality Initialization\n",
    "    # S_GANSCL= 'COMPLETE'           / Gain Scale Correction\n",
    "    # S_GRPSCL= 'COMPLETE'           / Group Scale Correction\n",
    "    # S_IPC   = 'SKIPPED '           / Interpixel Capacitance Correction\n",
    "    # S_JUMP  = 'COMPLETE'           / Jump Detection\n",
    "    # S_LINEAR= 'COMPLETE'           / Linearity Correction\n",
    "    # S_RAMP  = 'COMPLETE'           / Ramp Fitting\n",
    "    # S_REFPIX= 'COMPLETE'           / Reference Pixel Correction\n",
    "    # S_SATURA= 'COMPLETE'           / Saturation Checking\n",
    "    # S_SUPERB= 'COMPLETE'           / Superbias Subtraction\n",
    "\n",
    "    # Bad pixel mask overrides\n",
    "    # detector_1_pipeline.dq_init.override_mask = 'myfile.fits'\n",
    "\n",
    "    # Saturation overrides\n",
    "    # et1.saturation.override_saturation = 'myfile.fits'\n",
    "\n",
    "    # Reset overrides\n",
    "    # detector_1_pipeline.reset.override_reset = 'myfile.fits'\n",
    "\n",
    "    # Linearity overrides\n",
    "    # detector_1_pipeline.linearity.override_linearity = 'myfile.fits'\n",
    "\n",
    "    # RSCD overrides\n",
    "    # detector_1_pipeline.rscd.override_rscd = 'myfile.fits'\n",
    "\n",
    "    # DARK overrides\n",
    "    # detector_1_pipeline.dark_current.override_dark = 'myfile.fits'\n",
    "\n",
    "    # GAIN overrides\n",
    "    # detector_1_pipeline.jump.override_gain = 'myfile.fits'\n",
    "    # detector_1_pipeline.ramp_fit.override_gain = 'myfile.fits'\n",
    "\n",
    "    # READNOISE overrides\n",
    "    # detector_1_pipeline.jump.override_readnoise = 'myfile.fits'\n",
    "    # detector_1_pipeline.ramp_fit.override_readnoise = 'myfile.fits'\n",
    "\n",
    "    # JUMP overrides.\n",
    "    # Currently pipeline is not flagging lower-level jumps\n",
    "    # like we might want it to, so lower thresholds for more\n",
    "    # aggressive flagging.\n",
    "    # detector_1_pipeline.jump.save_results = True\n",
    "    # detector_1_pipeline.jump.rejection_threshold = 3.5  # default 4.0sigma\n",
    "    # detector_1_pipeline.jump.min_jump_to_flag_neighbors = 8.0  # default 10sigma\n",
    "\n",
    "    # Additional JUMP overrides related to CR shower flagging. See\n",
    "    # JWST pipeline documentation page for details of parameters.\n",
    "    # https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/index.html\n",
    "    detector_1_pipeline.jump.expand_large_events = True  # Turn on shower flagging\n",
    "    # detector_1_pipeline.jump.use_ellipses = True  # approximate showers as elliptical, obsolete in newest pipeline\n",
    "    # detector_1_pipeline.jump.min_jump_area = 12  # Min # of contiguous pixels to trigger expanded flagging\n",
    "    # detector_1_pipeline.jump.sat_required_snowball = False  # Require pixels to be saturated to flag\n",
    "    # detector_1_pipeline.jump.expand_factor = 3.0  # expands showers beyond ID'd jumps; default 2.0\n",
    "    #\n",
    "    # detector_1_pipeline.jump.after_jump_flag_dn1 = 10  # These 4 related to how long after a jump is identified\n",
    "    # detector_1_pipeline.jump.after_jump_flag_time1 = 20  #  we should keep flagging the following integrations\n",
    "    # detector_1_pipeline.jump.after_jump_flag_dn2 = 1000\n",
    "    # detector_1_pipeline.jump.after_jump_flag_time2 = 3000\n",
    "\n",
    "    ### settings from the original TEMPLATES notebook used for MIRI, for reference\n",
    "    # # JUMP overrides.\n",
    "    # # Currently pipeline is not flagging lower-level jumps\n",
    "    # # like we might want it to, so lower thresholds for more\n",
    "    # # aggressive flagging.\n",
    "    # #detector_1_pipeline.jump.save_results = True\n",
    "    # detector_1_pipeline.jump.rejection_threshold = 3.5         # default 4.0sigma\n",
    "    # detector_1_pipeline.jump.min_jump_to_flag_neighbors = 8.0  # default 10sigma\n",
    "    #\n",
    "    # # Additional JUMP overrides related to CR shower flagging. See\n",
    "    # # JWST pipeline documentation page for details of parameters.\n",
    "    # # https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/index.html\n",
    "    # detector_1_pipeline.jump.expand_large_events   = True   # Turn on shower flagging\n",
    "    # detector_1_pipeline.jump.use_ellipses          = True   # True for MIRI; approximate showers as elliptical\n",
    "    # detector_1_pipeline.jump.min_jump_area         = 8     # Min # of contiguous pixels to trigger expanded flagging\n",
    "    # # The saturated core allows the search for smaller events without false positives.\n",
    "    # detector_1_pipeline.jump.sat_required_snowball = False  # Do not require pixels to be saturated to flag\n",
    "    # detector_1_pipeline.jump.expand_factor         = 3.0    # expands showers beyond ID'd jumps; default 2.0\n",
    "    #\n",
    "    # detector_1_pipeline.jump.after_jump_flag_dn1   = 10     # These 4 related to how long after a jump is identified\n",
    "    # detector_1_pipeline.jump.after_jump_flag_time1 = 20     #  we should keep flagging the following integrations\n",
    "    # detector_1_pipeline.jump.after_jump_flag_dn2   = 1000\n",
    "    # detector_1_pipeline.jump.after_jump_flag_time2 = 3000\n",
    "    ### TEMPLATES settings end\n",
    "\n",
    "    # Ramp_fit overrides.\n",
    "    # detector_1_pipeline.ramp_fit.save_opt = True\n",
    "    # detector_1_pipeline.ramp_fit.save_results = True\n",
    "\n",
    "    detector_1_pipeline.save_results = True  # Save the final resulting _rate.fits files\n",
    "\n",
    "    detector_1_pipeline(file_name)  # Run the pipeline on an input list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa5be9346def8f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab a list of all uncal files from the folder\n",
    "files_uncal = sorted(glob.glob(uncal_directory + \"*nrs1_uncal.fits\"))\n",
    "\n",
    "# Run the Detector1 pipeline on each uncal exposure.\n",
    "if run_pipeline:\n",
    "    for file in tqdm(files_uncal):\n",
    "        run_spec1_pipeline(file_name=file, output_directory=stage1_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf9de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
