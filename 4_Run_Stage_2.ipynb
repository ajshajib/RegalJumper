{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13de4e742cb44935",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Author:** Anowar Shajib\n",
    "\n",
    "*With thanks to David Law.*\n",
    "\n",
    "In this notebook, we process our data through the Spec2 pipeline to produce Lvl2b data products, including calibrated slope images, quick-look data cubes, and 1D spectra.\n",
    "\n",
    "For more details, see the [Spec2 pipeline documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html).\n",
    "\n",
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources.\n",
    "\n",
    "If pixel-based background subtraction is chosen, it will be applied during Spec2. This requires creating an association file to associate the background files with individual science files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabf3138f78d804",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import median_filter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc173b82d2b21",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_pipeline = True\n",
    "subtract_leakcal_manual = True\n",
    "do_extra_cleaning = True\n",
    "subtract_pixel_based_background = False\n",
    "# Pixel-based background subtraction in spec2 (direct pixel subtraction) -Deep background exposures needed to not add noise.\n",
    "\n",
    "msa_leakage_file_ids = [\"10101\", \"12101\", \"14101\", \"16101\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28c92db31e803f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function that will call the spec2 pipeline with our desired set of parameters\n",
    "# We'll list the individual steps just to make it clear what's running\n",
    "\n",
    "\n",
    "def run_spec2_pipeline(\n",
    "    file_name, output_directory, no_cubes=False, is_background=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the Spec2Pipeline on a given file.\n",
    "\n",
    "    :param file_name: str, name of fits file to run pipeline on\n",
    "    :param output_directory: str, path to output directory\n",
    "    :param no_cubes: bool, if True, skip cube building and 1d spectral extraction\n",
    "    :return: None\n",
    "    :outputs:\n",
    "    \"\"\"\n",
    "    print(\"Running Detector2Pipeline on {0:s}...\".format(file_name))\n",
    "\n",
    "    # Set default configuration from CRDS param reference files.\n",
    "    # -This is required when running the pipeline in a function.\n",
    "    crds_config = Spec2Pipeline.get_config_from_reference(file_name)\n",
    "    spec2 = Spec2Pipeline.from_config_section(crds_config)\n",
    "\n",
    "    spec2.output_dir = output_directory\n",
    "\n",
    "    # Assign_wcs overrides\n",
    "    # spec2.assign_wcs.override_distortion = 'myfile.asdf'\n",
    "    # spec2.assign_wcs.override_regions = 'myfile.asdf'\n",
    "    # spec2.assign_wcs.override_specwcs = 'myfile.asdf'\n",
    "    # spec2.assign_wcs.override_wavelengthrange = 'myfile.asdf'\n",
    "\n",
    "    # Background overrides were set up above\n",
    "    if subtract_pixel_based_background:\n",
    "        spec2.bkg_subtract.skip = False\n",
    "    else:\n",
    "        spec2.bkg_subtract.skip = True\n",
    "\n",
    "    # Flatfield overrides\n",
    "    # spec2.flat_field.override_flat = 'myfile.fits'\n",
    "\n",
    "    # Straylight overrides\n",
    "    # spec2.straylight.override_mrsxartcorr = 'myfile.fits'\n",
    "\n",
    "    # Fringe overrides\n",
    "    # spec2.fringe.override_fringe = 'myfile.fits'\n",
    "\n",
    "    # Photom overrides\n",
    "    # spec2.photom.override_photom = 'myfile.fits'\n",
    "\n",
    "    # Cubepar overrides\n",
    "    # spec2.cube_build.override_cubepar = 'myfile.fits'\n",
    "\n",
    "    # Extract1D overrides\n",
    "    # spec2.extract_1d.override_extract1d = 'myfile.asdf'\n",
    "    # spec2.extract_1d.override_apcorr = 'myfile.asdf'\n",
    "\n",
    "    # Overrides for whether or not certain steps should be skipped\n",
    "    # spec2.assign_wcs.skip = False\n",
    "    # spec2.bkg_subtract.skip = True\n",
    "    # spec2.flat_field.skip = False\n",
    "    # spec2.srctype.skip = False\n",
    "    # spec2.straylight.skip = False\n",
    "    # spec2.fringe.skip = False\n",
    "    # spec2.photom.skip = False\n",
    "    # spec2.residual_fringe.skip = False #does a residual fringe correction across the entire cube\n",
    "    # spec2.cube_build.skip = False\n",
    "    # spec2.extract_1d.skip = False\n",
    "    spec2.nsclean.skip = True\n",
    "\n",
    "    # spec2.flat_field.override_sflat = \"./jwst_nirspec_sflat_0194_cleaned.fits\"\n",
    "\n",
    "    # Run pixel replacement code to extrapolate values for otherwise bad pixels.\n",
    "    # This can help mitigate small 5-10% negative dips in spectra of bright sources.\n",
    "    # spec2.pixel_replace.skip = True\n",
    "    # spec2.pixel_replace.algorithm='mingrad'\n",
    "\n",
    "    # This nocubes option allows us to skip the cube building and 1d spectral extraction for individual\n",
    "    # science data frames, but run it for the background data (as the 1d spectra are needed later\n",
    "    # for the master background step in Spec3)\n",
    "    if no_cubes:\n",
    "        spec2.cube_build.skip = True\n",
    "        spec2.extract_1d.skip = True\n",
    "\n",
    "    if is_background:\n",
    "        spec2.cube_build.skip = True\n",
    "        spec2.extract_1d.skip = True\n",
    "        spec2.bkg_subtract.skip = True\n",
    "\n",
    "    # Some cube building options\n",
    "    # spec2.cube_build.weighting='drizzle'\n",
    "    # spec2.cube_build.coord_system='ifualign' # If aligning cubes with IFU axes instead of sky\n",
    "\n",
    "    spec2.save_results = True\n",
    "    spec2(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subtract_leakcal_manual:\n",
    "    # Make a median leak image\n",
    "    all_files = np.array(\n",
    "        # sorted(glob.glob(rate_file_directory_for_processing + \"*nrs1_rate.fits\"))\n",
    "        sorted(glob.glob(stage1_nsclean_directory + \"*nrs1_rate.*fits\"))\n",
    "    )\n",
    "    leak_files = []\n",
    "    for file in all_files:\n",
    "        for msa_leakage_file_id in msa_leakage_file_ids:\n",
    "            if msa_leakage_file_id in file:\n",
    "                leak_files.append(file)\n",
    "                break\n",
    "\n",
    "    print(\"LeakCal files:\")\n",
    "    print(leak_files)\n",
    "\n",
    "    # Read in all the leak files\n",
    "    big_array = np.zeros([len(leak_files), 2048, 2048])\n",
    "    for i, leak_file in enumerate(leak_files):\n",
    "        with fits.open(leak_file) as hdu:\n",
    "            big_array[i, :, :] = hdu[\"SCI\"].data\n",
    "\n",
    "    median_leak = np.nanmedian(big_array, axis=0)\n",
    "\n",
    "    # Clean up the leak image\n",
    "    leak2 = median_leak.copy()\n",
    "\n",
    "    # First mask anything with counts > 0.5 DN/s\n",
    "    leak2[median_leak > 0.5] = np.nanmedian(leak2)\n",
    "\n",
    "    # Then deal with NaNs\n",
    "    leak2[np.isnan(leak2)] = np.nanmedian(leak2)\n",
    "\n",
    "    # Then apply a horizontal median filter to take out RMS noise\n",
    "    leak2 = median_filter(leak2, size=(1, 51))\n",
    "\n",
    "    # Subtract leak image from science files\n",
    "    sci_files = []\n",
    "    for file in all_files:\n",
    "        if file not in leak_files:\n",
    "            sci_files.append(file)\n",
    "\n",
    "    for sci_file in sci_files:\n",
    "        with fits.open(sci_file) as hdu:\n",
    "            sci = hdu[\"SCI\"].data\n",
    "            sci = sci - leak2\n",
    "            hdu[\"SCI\"].data = sci\n",
    "            name = pathlib.Path(sci_file).name\n",
    "            hdu.writeto(stage2_leakcal_directory + name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f70907bf1bbf96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rate_files = sorted(glob.glob(stage2_leakcal_directory + \"/*nrs1_rate.*fits\"))\n",
    "\n",
    "len(rate_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e30e962f27f8e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step through each of the science files, using relevant associated backgrounds in spec2 processing\n",
    "# The background files are used in this step to perform pixel-based background subtraction (if desired)\n",
    "# Otherwise Background subtraction is done later with Spec3 files\n",
    "if run_pipeline:\n",
    "    for file in tqdm(rate_files):\n",
    "        if \"01794002001\" in file:\n",
    "            is_background = True\n",
    "        else:\n",
    "            is_background = False\n",
    "\n",
    "        run_spec2_pipeline(\n",
    "            file,\n",
    "            output_directory=stage2_directory,\n",
    "            no_cubes=True,\n",
    "            is_background=is_background,\n",
    "        )\n",
    "else:\n",
    "    print(\"Skipping Spec2 processing for SCI data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997313d16b971fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extra processing to flag bad pixels again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcfea8c3ff85ece",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if do_extra_cleaning:\n",
    "    files = np.array(sorted(glob.glob(stage2_directory + \"/*nrs1_cal.fits\")))\n",
    "\n",
    "    for file in files:\n",
    "        with fits.open(file) as hdu:\n",
    "            sci = hdu[\"SCI\"].data\n",
    "\n",
    "            # Flag positive pixels\n",
    "            temp = sci.copy()\n",
    "            temp[np.isfinite(temp) != True] = 0.0\n",
    "            sci2 = median_filter(temp, size=(1, 11))\n",
    "            diff = temp - sci2 * 2\n",
    "            index = np.where(diff > 100)\n",
    "            sci[index] = np.nan\n",
    "            # Grow by 1 pixel in both directions\n",
    "            y_index = index[1]\n",
    "            x_index = index[0]\n",
    "            n_index = len(y_index)\n",
    "            for i in range(n_index):\n",
    "                sci[x_index[i] - 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i] + 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i], y_index[i] - 1] = np.nan\n",
    "                sci[x_index[i], y_index[i] + 1] = np.nan\n",
    "                for u in range(-1, 2):\n",
    "                    for v in range(-1, 2):\n",
    "                        sci[x_index[i] + u, y_index[i] + v] = np.nan\n",
    "\n",
    "            # Flag negative pixels\n",
    "            temp = sci.copy()\n",
    "            temp[np.isfinite(temp) != True] = 0.0\n",
    "            sci2 = median_filter(temp, size=(1, 11))\n",
    "            diff = temp - sci2 * 0.5\n",
    "            index = np.where(diff < -100)\n",
    "            sci[index] = np.nan\n",
    "            # Grow by 1 pixel in both directions\n",
    "            y_index = index[1]\n",
    "            x_index = index[0]\n",
    "            n_index = len(y_index)\n",
    "            for i in range(n_index):\n",
    "                sci[x_index[i] - 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i] + 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i], y_index[i] - 1] = np.nan\n",
    "                sci[x_index[i], y_index[i] + 1] = np.nan\n",
    "                for u in range(-1, 2):\n",
    "                    for v in range(-1, 2):\n",
    "                        sci[x_index[i] + u, y_index[i] + v] = np.nan\n",
    "\n",
    "            hdu[\"SCI\"].data = sci\n",
    "            name = pathlib.Path(file).name\n",
    "            hdu.writeto(stage2_processed_directory + name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3debb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
