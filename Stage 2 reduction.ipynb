{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Authors:** Anowar Shajib, David Law\n",
    "\n",
    "*Adapted from the [notebook](https://github.com/JWST-Templates/Notebooks/blob/main/MIRI_MRS_reduction_SPT0418-47_PAH_ch3long.ipynb) by the TEMPLATES team (J. Spilker, K. A. Phadke, D. Law).*\n",
    "\n",
    "In this notebook we process our data through the Spec2 pipeline in order to produce \n",
    "Lvl2b data products (i.e., calibrated slope images and quick-look data cubes and 1d spectra).  \n",
    "    \n",
    "See https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html\n",
    "\n",
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources (as of DMS build 9.3/CAL_VER 1.10.2). \n",
    "\n",
    "If Pixel-based background subtraction was chosen, this will be applied during Spec2. \n",
    "Doing the Pixel based background subtraction requires an association file to be created to associate the background files with individual science files."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13de4e742cb44935"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "from scipy.ndimage import median_filter\n",
    "from util import *"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efabf3138f78d804"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_pipeline = True\n",
    "run_on_nsclean_data = True\n",
    "do_extra_processing = True\n",
    "subtract_pixel_based_background = False\n",
    "# Pixel-based background subtraction in spec2 (direct pixel subtraction) -Deep background exposures needed to not add noise.\n",
    "\n",
    "if run_on_nsclean_data:\n",
    "    stage1_directory = stage1_nsclean_directory\n",
    "    stage2_directory = stage2_nsclean_directory\n",
    "else:\n",
    "    stage1_directory = stage1_processed_directory\n",
    "    stage2_directory = stage2_directory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bc173b82d2b21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function that will call the spec2 pipeline with our desired set of parameters\n",
    "# We'll list the individual steps just to make it clear what's running\n",
    "def run_spec2_pipeline(file_name, output_directory, no_cubes=False,\n",
    "                       is_background=False\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    Run the Spec2Pipeline on a given file.\n",
    "\n",
    "    :param file_name: str, name of fits file to run pipeline on\n",
    "    :param output_directory: str, path to output directory\n",
    "    :param no_cubes: bool, if True, skip cube building and 1d spectral extraction\n",
    "    :return: None\n",
    "    :outputs:\n",
    "    \"\"\"\n",
    "    print(\"Running Detector2Pipeline on {0:s}...\".format(file_name))\n",
    "\n",
    "    # Set default configuration from CRDS param reference files.\n",
    "    # -This is required when running the pipeline in a function.\n",
    "    crds_config = Spec2Pipeline.get_config_from_reference(file_name)\n",
    "    spec2 = Spec2Pipeline.from_config_section(crds_config)\n",
    "\n",
    "    spec2.output_dir = output_directory\n",
    "\n",
    "    # Assign_wcs overrides\n",
    "    # spec2.assign_wcs.override_distortion = 'myfile.asdf'\n",
    "    # spec2.assign_wcs.override_regions = 'myfile.asdf'\n",
    "    # spec2.assign_wcs.override_specwcs = 'myfile.asdf'\n",
    "    # spec2.assign_wcs.override_wavelengthrange = 'myfile.asdf'\n",
    "\n",
    "    # Background overrides were set up above\n",
    "    if subtract_pixel_based_background:\n",
    "        spec2.bkg_subtract.skip = False\n",
    "    else:\n",
    "        spec2.bkg_subtract.skip = True\n",
    "\n",
    "    # Flatfield overrides\n",
    "    # spec2.flat_field.override_flat = 'myfile.fits'\n",
    "\n",
    "    # Straylight overrides\n",
    "    # spec2.straylight.override_mrsxartcorr = 'myfile.fits'\n",
    "\n",
    "    # Fringe overrides\n",
    "    # spec2.fringe.override_fringe = 'myfile.fits'\n",
    "\n",
    "    # Photom overrides\n",
    "    # spec2.photom.override_photom = 'myfile.fits'\n",
    "\n",
    "    # Cubepar overrides\n",
    "    # spec2.cube_build.override_cubepar = 'myfile.fits'\n",
    "\n",
    "    # Extract1D overrides\n",
    "    # spec2.extract_1d.override_extract1d = 'myfile.asdf'\n",
    "    # spec2.extract_1d.override_apcorr = 'myfile.asdf'\n",
    "\n",
    "    # Overrides for whether or not certain steps should be skipped\n",
    "    # spec2.assign_wcs.skip = False\n",
    "    # spec2.bkg_subtract.skip = True\n",
    "    # spec2.flat_field.skip = False\n",
    "    # spec2.srctype.skip = False\n",
    "    # spec2.straylight.skip = False\n",
    "    # spec2.fringe.skip = False\n",
    "    # spec2.photom.skip = False\n",
    "    # spec2.residual_fringe.skip = False #does a residual fringe correction across the entire cube\n",
    "    # spec2.cube_build.skip = False\n",
    "    # spec2.extract_1d.skip = False\n",
    "\n",
    "    spec2.flat_field.override_sflat = \"./jwst_nirspec_sflat_0194_cleaned.fits\"\n",
    "\n",
    "    # Run pixel replacement code to extrapolate values for otherwise bad pixels.\n",
    "    # This can help mitigate small 5-10% negative dips in spectra of bright sources.\n",
    "    spec2.pixel_replace.skip = True\n",
    "    # spec2.pixel_replace.algorithm='mingrad'\n",
    "\n",
    "    # This nocubes option allows us to skip the cube building and 1d spectral extraction for individual\n",
    "    # science data frames, but run it for the background data (as the 1d spectra are needed later\n",
    "    # for the master background step in Spec3)\n",
    "    if no_cubes:\n",
    "        spec2.cube_build.skip = True\n",
    "        spec2.extract_1d.skip = True\n",
    "    \n",
    "    if is_background:\n",
    "        spec2.extract_1d.skip = False\n",
    "        spec2.bkg_subtract.skip = True\n",
    "        \n",
    "    # Some cube building options\n",
    "    # spec2.cube_build.weighting='drizzle'\n",
    "    # spec2.cube_build.coord_system='ifualign' # If aligning cubes with IFU axes instead of sky\n",
    "\n",
    "    spec2.save_results = True\n",
    "    spec2(file_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd28c92db31e803f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rate_files = sorted(glob.glob(stage1_processed_directory + \"/*nrs1_rate.fits\"))\n",
    "\n",
    "len(rate_files)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52f70907bf1bbf96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step through each of the science files, using relevant associated backgrounds in spec2 processing\n",
    "# The background files are used in this step to perform pixel-based background subtraction (if desired)\n",
    "# Otherwise Background subtraction is done later with Spec3 files\n",
    "if run_pipeline:\n",
    "    for file in tqdm(rate_files):\n",
    "        if \"01794002001\" in file:\n",
    "            is_background = True\n",
    "        else:\n",
    "            is_background = False\n",
    "        \n",
    "        run_spec2_pipeline(file, output_directory=stage2_directory, no_cubes=True,\n",
    "                           is_background=is_background)\n",
    "else:\n",
    "    print(\"Skipping Spec2 processing for SCI data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8e30e962f27f8e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra processing to flag bad pixels again"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2997313d16b971fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if do_extra_processing:\n",
    "    files = np.array(sorted(glob.glob(stage2_directory + \"/*nrs1_cal.fits\")))\n",
    "\n",
    "    for file in files:\n",
    "        with fits.open(file) as hdu:\n",
    "            sci = hdu[\"SCI\"].data\n",
    "\n",
    "            # Flag positive pixels\n",
    "            temp = sci.copy()\n",
    "            temp[np.isfinite(temp) != True] = 0.0\n",
    "            sci2 = median_filter(temp, size=(1, 11))\n",
    "            diff = temp - sci2 * 2\n",
    "            index = np.where(diff > 100)\n",
    "            sci[index] = np.nan\n",
    "            # Grow by 1 pixel in both directions\n",
    "            y_index = index[1]\n",
    "            x_index = index[0]\n",
    "            n_index = len(y_index)\n",
    "            for i in range(n_index):\n",
    "                sci[x_index[i] - 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i] + 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i], y_index[i] - 1] = np.nan\n",
    "                sci[x_index[i], y_index[i] + 1] = np.nan\n",
    "\n",
    "            # Flag negative pixels\n",
    "            temp = sci.copy()\n",
    "            temp[np.isfinite(temp) != True] = 0.0\n",
    "            sci2 = median_filter(temp, size=(1, 11))\n",
    "            diff = temp - sci2 * 0.5\n",
    "            index = np.where(diff < -100)\n",
    "            sci[index] = np.nan\n",
    "            # Grow by 1 pixel in both directions\n",
    "            y_index = index[1]\n",
    "            x_index = index[0]\n",
    "            n_index = len(y_index)\n",
    "            for i in range(n_index):\n",
    "                sci[x_index[i] - 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i] + 1, y_index[i]] = np.nan\n",
    "                sci[x_index[i], y_index[i] - 1] = np.nan\n",
    "                sci[x_index[i], y_index[i] + 1] = np.nan\n",
    "\n",
    "            hdu[\"SCI\"].data = sci\n",
    "            name = pathlib.Path(file).name\n",
    "            hdu.writeto(stage2_processed_directory + name, overwrite=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bcfea8c3ff85ece"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
